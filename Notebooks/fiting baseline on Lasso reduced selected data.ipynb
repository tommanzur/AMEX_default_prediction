{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/usuario/workspace/AMEX_data/train_data_LASSO_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_44</th>\n",
       "      <th>...</th>\n",
       "      <th>B_30_1.0</th>\n",
       "      <th>B_38_2.0</th>\n",
       "      <th>B_38_3.0</th>\n",
       "      <th>B_38_4.0</th>\n",
       "      <th>D_114_1.0</th>\n",
       "      <th>D_117_4.0</th>\n",
       "      <th>D_120_1.0</th>\n",
       "      <th>D_64_O</th>\n",
       "      <th>D_68_6.0</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.934570</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>1.007812</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.135010</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.007175</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.880371</td>\n",
       "      <td>0.178101</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>1.003906</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.165527</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.164795</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0.621582</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>1.005859</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.287842</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.009941</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.872070</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.815918</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.164795</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456642</th>\n",
       "      <td>ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>0.447510</td>\n",
       "      <td>0.028519</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.128662</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456643</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>0.831055</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>0.292480</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.164795</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.233032</td>\n",
       "      <td>0.132202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456644</th>\n",
       "      <td>ffff9984b999fccb2b6127635ed0736dda94e544e67e02...</td>\n",
       "      <td>0.800293</td>\n",
       "      <td>0.267090</td>\n",
       "      <td>0.020569</td>\n",
       "      <td>1.006836</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.066650</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456645</th>\n",
       "      <td>ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.408936</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.050049</td>\n",
       "      <td>0.133057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456646</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>0.981934</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.992676</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.119141</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456647 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Unnamed: 0       P_2      D_39  \\\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.934570  0.009117   \n",
       "1       00000fd6641609c6ece5454664794f0340ad84dddce9a2...  0.880371  0.178101   \n",
       "2       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...  0.880859  0.009705   \n",
       "3       000041bdba6ecadd89a52d11886e8eaaec9325906c9723...  0.621582  0.001082   \n",
       "4       00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...  0.872070  0.005573   \n",
       "...                                                   ...       ...       ...   \n",
       "456642  ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...  0.844238  0.447510   \n",
       "456643  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...  0.831055  0.033661   \n",
       "456644  ffff9984b999fccb2b6127635ed0736dda94e544e67e02...  0.800293  0.267090   \n",
       "456645  ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...  0.753906  0.008621   \n",
       "456646  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  0.981934  0.002474   \n",
       "\n",
       "             B_1       B_2       R_1       S_3      D_41       B_3      D_44  \\\n",
       "0       0.009384  1.007812  0.006104  0.135010  0.001604  0.007175  0.003258   \n",
       "1       0.034698  1.003906  0.006912  0.165527  0.005550  0.005070  0.008781   \n",
       "2       0.004284  0.812500  0.006451  0.164795  0.003796  0.007195  0.000628   \n",
       "3       0.012566  1.005859  0.007828  0.287842  0.004532  0.009941  0.007793   \n",
       "4       0.007679  0.815918  0.001247  0.164795  0.000231  0.005527  0.002436   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "456642  0.028519  1.009766  0.001928  0.128662  0.003483  0.005894  0.002281   \n",
       "456643  0.292480  0.055664  0.006954  0.164795  0.005791  0.233032  0.132202   \n",
       "456644  0.020569  1.006836  0.000957  0.066650  0.007423  0.006313  0.001022   \n",
       "456645  0.015839  0.714355  0.000993  0.408936  0.003391  0.050049  0.133057   \n",
       "456646  0.000077  0.992676  0.000809  0.119141  0.003286  0.014091  0.006794   \n",
       "\n",
       "        ...  B_30_1.0  B_38_2.0  B_38_3.0  B_38_4.0  D_114_1.0  D_117_4.0  \\\n",
       "0       ...       0.0       1.0       0.0       0.0        1.0        1.0   \n",
       "1       ...       0.0       1.0       0.0       0.0        1.0        0.0   \n",
       "2       ...       0.0       0.0       0.0       0.0        1.0        0.0   \n",
       "3       ...       0.0       1.0       0.0       0.0        1.0        0.0   \n",
       "4       ...       0.0       0.0       0.0       0.0        1.0        1.0   \n",
       "...     ...       ...       ...       ...       ...        ...        ...   \n",
       "456642  ...       0.0       1.0       0.0       0.0        0.0        0.0   \n",
       "456643  ...       0.0       0.0       0.0       0.0        1.0        0.0   \n",
       "456644  ...       0.0       0.0       1.0       0.0        1.0        0.0   \n",
       "456645  ...       0.0       0.0       1.0       0.0        1.0        0.0   \n",
       "456646  ...       0.0       0.0       1.0       0.0        1.0        0.0   \n",
       "\n",
       "        D_120_1.0  D_64_O  D_68_6.0  target  \n",
       "0             0.0     1.0       1.0       0  \n",
       "1             0.0     1.0       1.0       0  \n",
       "2             0.0     0.0       1.0       0  \n",
       "3             0.0     1.0       0.0       0  \n",
       "4             0.0     1.0       1.0       0  \n",
       "...           ...     ...       ...     ...  \n",
       "456642        1.0     0.0       1.0       0  \n",
       "456643        0.0     0.0       1.0       0  \n",
       "456644        0.0     0.0       0.0       0  \n",
       "456645        0.0     0.0       0.0       1  \n",
       "456646        0.0     1.0       0.0       0  \n",
       "\n",
       "[456647 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 433 ms, total: 1.69 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Conservamos el último registro de cada usuario\n",
    "df =  (df\n",
    "            .groupby('Unnamed: 0')\n",
    "            .tail(1)\n",
    "            .set_index('Unnamed: 0', drop=True)\n",
    "            .sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = df.columns.to_list()\n",
    "\n",
    "cat_cols = [cname for cname in df.columns if df[cname].nunique() < 10 and \n",
    "                        df[cname].dtype == \"object\"]\n",
    "\n",
    "num_cols = [col for col in all_cols if col not in cat_cols + [\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((456647, 46), (456647,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[cat_cols + num_cols]\n",
    "y = df['target']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construimos las linea de base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partimos el conjunto de datos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construimos el pipeline completo en tres pasos.\n",
    "\n",
    "* Paso 1: definimos los pasos de preprocesamiento\n",
    "De manera similar a el pipeline agrupa los pasos de preprocesamiento y modelado, usamos la clase ColumnTransformer para agrupar diferentes pasos de preprocesamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#El código a continuación imputa valores faltantes en datos numéricos, e\n",
    "#imputa valores faltantes y aplica una codificación one-hot a los datos categóricos.\n",
    "\n",
    "# Preprocesando la data numérica\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Preprocesando la data categórica\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Paso 2: Definimos el modelo. En este caso para la linea de base utilizaremos una regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "semilla = 1234\n",
    "model = LogisticRegression(random_state=semilla, max_iter=200, solver=\"saga\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Paso 3: crear y evaluar el pipeline\n",
    "Finalmente, usamos la clase Pipeline para definir un pipeline que agrupa los pasos de preprocesamiento y modelado. Hay algunas cosas importantes a tener en cuenta:\n",
    "\n",
    "Con el pipeline, preprocesamos los datos de entrenamiento y ajustamos el modelo en una sola línea de código. (Por el contrario, sin un pipeline, tendríamos que hacer la imputación, la codificación one-hot y el entrenamiento del modelo en pasos separados.\n",
    "\n",
    "Con el pipeline proporcionamos las funciones no procesadas en X_test al comando predict(), y el pipeline preprocesa automáticamente las funciones antes de generar predicciones. (Sin embargo, sin el pipeline, debemos recordar preprocesar los datos de validación antes de hacer predicciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Paquete de preprocesamiento y código de modelado\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', model)\n",
    "                             ])\n",
    "\n",
    "# Preprocesamiento de datos de entrenamiento, ajuste del modelo\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocesamiento de datos de validación, obtener predicciones\n",
    "preds = my_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79134  5443]\n",
      " [ 7676 21909]]\n",
      "El accuracy score para el modelo base es: 0.8850843538130025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test,preds)\n",
    "print(cm)\n",
    "print(f'El accuracy score para el modelo base es: {accuracy_score(y_test, preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12bb187c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEJCAYAAABfZHZuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwUxf3/8dd7lxsEAQWRQ1DwABNRDEFNvFBBRFGDigmK/jZiFA+MGsH4jebA6+sRjyhBScQLQaJf8cIoKF7AigdyiEJAYZUACgIq18Ln90fXwrDszvYuO7szs5+nj35Md3VXTzXOfqamurpKZoZzzrnMkFPdBXDOORefB23nnMsgHrSdcy6DeNB2zrkM4kHbOecyiAdt55zLILVS/Qb1253rfQrdTtYv+WN1F8Glpf21q2coT8xZv2TsLr9fVUt50HbOuaokZXcDggdt51xWUZa3+nrQds5llZyc7A5r2X11zrkaR8q4Zupy8aDtnMsy3jzinHMZw29EOudcBvGg7ZxzGcR7jzjnXAbx3iPOOZdBvHnEOecyiPAuf845lzG8pu2ccxnEg7ZzzmUQD9rOOZdBpOwOa9l9dc65Gsdr2s45l0H84RrnnMsgXtN2zrkM4kOzOudcBsnxG5HOOZc5vHnEOecySLYH7ey+OudcjSNyYi9JzyMdIOmjhGWtpKGSmkl6VdKC8No0Ic9wSQslfSqpV0J6N0mzw757FRreJdWVNC6kz5DUvqzr86DtnMsuyom/JGFmn5pZVzPrCnQDfgCeBYYBk82sEzA5bCOpMzAA6AL0Bh6QlBtO9yAwGOgUlt4hPQ9YbWYdgbuB28q6PA/azrmsIuXEXsqhJ/AfM/sC6AeMCeljgNPDej/gKTPbaGaLgYVAd0mtgMZmNs3MDHi0WJ6ic00AeqqM7i/epu2cyyo52yq3lWoAMDastzSzZQBmtkxSi5DeGpiekKcgpG0O68XTi/IsDecqlLQGaA58XVpBvKbtnMsq5alpSxosaWbCMnjn86kOcBrwdFlvXUKaJUlPlqdUXtN2zmWXcjxcY2ajgFFlHHYy8IGZLQ/byyW1CrXsVsCKkF4AtE3I1wb4KqS3KSE9MU+BopGumgCrkhXGa9rOueySU44lnnPZ3jQCMBEYFNYHAc8lpA8IPUI6EN1wzA9NKesk9Qjt1ecXy1N0rv7AlNDuXSqvaTvnskslPsYuqQFwInBxQvKtwHhJecAS4CwAM5sraTwwDygEhpjZlpDnEuARoD7wclgARgOPSVpIVMMeUFaZPGg757JLJQZtM/uB6MZgYto3RL1JSjp+BDCihPSZwMElpG8gBP24PGg757KK5fqAUc45lzmyO2Z70HbOZZmc7I7aHrSdc9nFx9N2zrkMkt0x24O2cy7L5Gb34ycetJ1z2cVr2s45l0H8RqRzzmWQ7I7ZHrSdc9nFvPeIc85lEG8ecc65DOJB2znnMogHbeecyyDZHbM9aDvnsozfiHTOuQziQds55zJIdj/F7kHbOZdl/EakS9Rp31Y89rcrtm13aNeCP981ganvzuW+m/No2LAeXxSs5MIr/sa679bTbPdGPDlyKN0O2Y/Hn57KVX94ZFve5x4dxl4tdqdWrVzeyZ/P0Bv+wdat2+f0PKNPd54ceRVH9f09H3y8qCov0+2i44/Po2HD+uTk5JCbm8szz9y9bd/o0c9w++3/ZNq0x2nWrMm29K++WsEppwzhssvOJS/vTADy8m5k5cpVbNmyhW7dunDjjb8hNze3yq8nk5gHbZdowaJl9Dh5OAA5OeI/+Q8wcdJ7PDlyKMP+8gRvz/iE888+lqsu7suf7nyaDRs386c7n6bzAW3psn+bHc418NJ7WPfdegDGjhzKL07pwdPPTwOgUcN6XHphb/I/WFC1F+gqzZgxI3YIygDLlq3k3Xc/Yu+999zp+FtueZif/7zbDmn33HMdjRo1wMy44opbmDTpHU455eiUljvjZXmbdoVafyS9XPZR2e+4ow5m8ZLlLPnyazrt24q3Z3wCwJS3Pub0Pt0B+GH9Rt5971M2bNi0U/6igF2rVi6169TC2F7LvvGas7lr5PNs2Li5Cq7EVZVbbnmYa6+9EBULLK+9No02bfaiU6d2O6Q3atQAgMLCLWzeXLhTPlcClWPJQKUGbUmHlbJ0A7pWYRnT1lmnHcn4594FYN6nBfQ9MaolnXlKD9q0ap4s6zYTHxvGkg9H8t13G3jmxRkAHNKlPW1aNePlyR+mpuCuSuTl/YEzzxzKuHGTAJg8eQYtWjTnwAM77HDcDz9s4KGH/sVll51b6nmOPHIgDRvWp1evI1Ne7oyXo/hLGSTtLmmCpPmSPpF0hKRmkl6VtCC8Nk04frikhZI+ldQrIb2bpNlh370K376S6koaF9JnSGpf5uUl2fcecAdwZ7HlDmD3Mi50sKSZkmYWfrewrDJkpNq1cznlxG7bAu3F1/6diwedxDsvjqBRo/ps2lwY6zynnXcrHQ6/lLp1anHsUQcjidv/cB7X/eXxVBbfpdjYsbfz7LP38NBDN/HEEy/y3ntzGDlyPFde+audjr3vvicYNKgfDRvWL/Fco0f/ibfffpRNmzYzffrHqS565qvEoA3cA0wyswOBQ4BPgGHAZDPrBEwO20jqDAwAugC9gQckFd2AeBAYDHQKS++QngesNrOOwN3AbWUVKFmb9ifAxWa2U6OqpKXJTmpmo4BRAPXbnWvJjs1UvY7tykdzFrPi6zUAfPafrzh14C0AdOywFycfH//HyMaNm3nhtQ849cRuzPxoIZ0PaMu/x/0BgJZ7NmHC6Gvon3eH34zMIC1bRr+0mjffnRNPPIL8/DkUFCynX7/oJvZ///s1Z545lKefvotZsz7jlVfe5Y47HmHt2u/JyRF169Zh4MC+285Xt24djj/+p0yePIOjjjq0Wq4pY1TSjUhJjYGjgQsAzGwTsElSP+DYcNgY4A3gOqAf8JSZbQQWS1oIdJf0OdDYzKaF8z4KnA68HPLcFM41Abhfksys1LiZLGjfROk18cuT5KsRzu63vWkEYM/mjVn5zVokMeyKM3jo8clJ8zdsUJfdGtXnvyu+JTc3h97HdeWd/PmsXbeetl0HbzvulXH/w/ART3jAziA//LCBrVu30qhRA374YQPvvPMhl146gGnTtv96Ov74PCZMuItmzZrw5JPbK1f33fckDRrUY+DAvnz//Xq+/349LVo0o7BwC1OnzuTww7tUxyVllnIEbUmDiWrARUaFSifAvsBK4J+SDgHeB64EWprZMgAzWyapRTi+NTA94VwFIW1zWC+eXpRnaThXoaQ1QHPg69LKXGrQNrMJSfb9X2n7aoL69epw/M9/xGXDH96Wdna/I7n4/JMAeG5SPo+Of2Pbvvnv3Mtuu9WnTu1anNrrcPoOvIVVq79jwuhrqFOnNrm5OUx9Zy4PPf5aVV+KS4FvvvmWIUNGALBlyxb69j2Go4/uVkauna1fv4FLLvkzmzYVsnXrFnr0OIQBA06u7OJmHStHRTuxVaAEtYDDgMvNbIakewhNIaUo6Z0tSXqyPKW/SZJa+PaDpMPM7IPStpPJ1uYRt2vWL/ljdRfBpaX9d7ltY9/BE2LHnEWj+pf6fpL2AqabWfuw/XOioN0RODbUslsBb5jZAZKGA5jZLeH4V4haLD4HXg/t4kg6N+S/uOgYM5smqRbwX2DPZM0jcbv8XVLGtnPOpQcp/pKEmf0XWCrpgJDUE5gHTAQGhbRBwHNhfSIwIPQI6UB0wzE/NKWsk9Qj9Bo5v1ieonP1B6YkC9gQ8+EaM7so2bZzzqWNWpXaAfty4AlJdYBFwIVEld3xkvKAJcBZAGY2V9J4osBeCAwxsy3hPJcAjwD1iW5AFj3rMhp4LNy0XEXU+ySpMoN2+Gb4FbCvmf1JUjtgLzPLj3XJzjlXlSrxASQz+wg4vIRdPUs5fgQwooT0mcDBJaRvIAT9uOI0jzwAHAEU9fxfB/ytPG/inHNVpnL7aaedOM0jPzWzwyR9CGBmq8NPBeecSzs+GztsDk/1GICkPYGtKS2Vc85VlI+nzb3As0ALSSOI7nDekNJSOedcReVmd9QuM2ib2ROS3idqeBdwupl9kvKSOedcRWRoW3VccXqP3AOMMzO/+eicS3/ZHbNjtf58ANwQhg78X0kldX9xzrm0YDmKvWSiMoO2mY0xsz5Ad+Az4DZJPp2Kcy49eZe/bToCBwLtiZ74cc659FPTu/xJug04E/gPMB74s5l9m+qCOedcheTW8KANLAaOMLNSx3d1zrm0kaHNHnGVGrQlHWhm84F8oF0Yc2SbuEOzOudclaqpQRv4LdGMDneWsM+A41NSIuec2wU19jF2MyuagufkMBLVNpLqpbRUzjlXUdn9QGSsy3s3ZppzzlW/SpoEIV0la9Pei2jSyfqSDmX7c0aNgQZVUDbnnCu/Wtld1U7Wpt2LaOr4NsBdCenrgOtTWCbnnKu4zKxAx5asTXsMMEbSL8zsX1VYJuecq7BMfTw9rmTNIwPN7HGgvaTfFt9vZneVkM0556pXhrZVx5WseaRheG1UFQVxzrlKUVNr2mb29/D6x6orjnPO7Zqc3Mo7l6TPie7jbQEKzexwSc2AcUTjMH0OnG1mq8Pxw4G8cPwVZvZKSO/G9tnYXwKuNDOTVBd4FOgGfAOcY2afJ72+GIW+XVJjSbUlTZb0taSB5bx255yrEino8XecmXU1s6JhqYcBk82sEzA5bCOpMzAA6AL0Bh4IUzUCPEj0sGKnsPQO6XnAajPrCNwN3FZWYeL0jTnJzNYCfYECYH/g2hj5nHOuylVBN+1+wJiwPgY4PSH9KTPbaGaLgYVAd0mtgMZmNs3MjKhmfXoJ55oA9JSSlyxO0K4dXvsAY81sVYw8zjlXLSTFXmIw4N+S3pdU9JR4SzNbBhBeW4T01sDShLwFIa11WC+evkMeMysE1gDNkxUozih/z0uaD6wHLg2zsW8oI49zzlWL8tSgQyAenJA0ysxGJWwfZWZfSWoBvBpiYamnKyHNkqQny1OqOBP7Dgtjaq81sy2Svieq0jvnXNopT9AOAXpUkv1fhdcVkp4lmsFruaRWZrYsNH2sCIcXAG0TsrcBvgrpbUpIT8xTIKkW0ARI2poR50ZkbeA8YJykCUQN59+Ulc8556pDTm78JRlJDSXtVrQOnATMASYCg8Jhg4DnwvpEYICkupI6EN1wzA9NKOsk9Qjt1ecXy1N0rv7AlNDuXao4zSMPErVrPxC2zwtpv46R1znnqlQldtNuCTwb2r5rAU+a2SRJ7wHjJeUBS4CzAMxsrqTxRNMxFgJDzGxLONclbO/y93JYAEYDj0laSFTDHlBWoeIE7Z+Y2SEJ21MkzYqRzznnqlxlPRBpZouAQ0pI/wboWUqeEcCIEtJnAgeXkL6BEPTjitN7ZIuk/Yo2JO1L1HHcOefSTpaPzBqrpn0t8LqkRUR3OvcBLkxpqZxzroJiduXLWEmDdujet4bojmkLoqA938w2VkHZnHOu3JTdw2mX3jwi6dfAXOA+4COgvZnN8oDtnEtnOTnxl0yUrKY9FOhiZitDO/YTRN1TnHMubWV560jSoL3JzFZCdBc1jEblnHNpLctHZk0atNtIure0bTO7InXFcs65iqnJNe3iI/m9n8qCOOdcZaixQTvMEemccxklJze7o3acftrOOZcxamxN2znnMlG2B+04o/wdFSfNOefSQY7iL5koTvfy+2KmOedctauxY49IOgI4EthT0m8TdjUGKnG+Y+ecqzzZ/hh7sjbtOkCjcMxuCelriQbrds65tJOTqe0eMSXr8jcVmCrpETP7ogrL5JxzFZapzR5xxfkh8bCk3Ys2JDWV9EoKy+SccxVWY9u0E+xhZt8WbZjZ6jAzcSzrPh9WoYK57PbRN59VdxFcGurafP9dPkemBuO44tS0t0pqV7QhaR/KmOLdOeeqS7Z3+YtT0/498LakqWH7aGBw6orknHMVl6nBOK4yg3aYffgwoAfRzDVXmdnXKS+Zc85VQK2c7G4ISDZzzYHh9TCgHfAV8CXQLqQ551zaySnHEoekXEkfSnohbDeT9KqkBeG1acKxwyUtlPSppF4J6d0kzQ777lWYyFJSXUnjQvoMSe3LKk+ymvbVwEXAnSXsM+D4WFfsnHNVKEeVXtO+EviE6MFCgGHAZDO7VdKwsH2dpM7AAKALsDfwmqT9zWwL8CBRs/J04CWgN/AykAesNrOOkgYAtwHnJCtMsn7aF4XX4yp6pc45V9Uqs01bUhvgFGAEUPRkeD/g2LA+BngDuC6kPxXm0V0saSHQXdLnQGMzmxbO+ShwOlHQ7gfcFM41Abhfksys1G+eZI+xn5nsYszsmWT7nXOuOpTnKXZJg9mxY8UoMxuVsP1X4Hfs+FR4SzNbBmBmyxK6QLcmqkkXKQhpm8N68fSiPEvDuQolrQGaA6XeN0zWPHJqeG1BNAbJlLB9HNE3iwdt51zayS3HjcgQoEeVtE9SX2CFmb0v6dgYpyupjm9J0pPlKVWy5pELAULje+eibxZJrYC/JTupc85Vl0psHjkKOE1SH6Ae0FjS48BySa1CLbsVsCIcXwC0TcjfhqgDR0FYL56emKdAUi2gCbAqWaHi/JJoXxSwg+XArj+25JxzKVBZvUfMbLiZtTGz9kQ3GKeY2UBgIjAoHDYIeC6sTwQGhB4hHYBOQH6In+sk9Qi9Rs4vlqfoXP3De1Sspp3gjTDWyFiiavsA4PUY+ZxzrsqloPdIcbcC4yXlAUuAswDMbK6k8cA8oBAYEnqOAFwCPALUJ7oB+XJIHw08Fm5ariKKr0mpjKAeHSSdQfQkJMCbZvZsrEsDCrfOyu6e7q5C5qxeWt1FcGmoa/O+u9y4MXDq1Ngx5/Fjjsm45yfjzhH5AbDOzF6T1EDSbma2LpUFc865isjyORDKDtqSLiLqEtMM2I+oi8pIoGdqi+acc+VXYx9jTzCE6C7qWgAzW0DUDdA559KOj/IHG81sU3hUntAtJbu/ypxzGavGN48QTTl2PVBf0onApcDzqS2Wc85VTBX0HqlWcb6UrgNWArOBi4kGO7khlYVyzrmKqtHNI5JygI/N7GDgoaopknPOVVytDA3GcSUN2ma2VdIsSe3MbElVFco55yoq25tH4rRptwLmSsoHvi9KNLPTUlYq55yroExt9ogrTtD+Y8pL4ZxzlaTG9h6RVA/4DdCR6CbkaDMrrKqCOedcRdTkmvYYosG73wJOBjoTTbvjnHNpSzW4Tbuzmf0IQNJoIL9qiuSccxVXk3uPbC5aCdPgVEFxnHNu19Tk3iOHSFob1kX0ROTasG5m1rj0rM45Vz1qbJu2meVWZUGcc64y1Nig7ZxzmSjba5setJ1zWaUmt2k751zGqZXlT9d40HbOZZXcLG/TzvLvJOdcTVNZQ7NKqicpPwyaN1fSH0N6M0mvSloQXpsm5BkuaaGkTyX1SkjvJml22HevQh9qSXUljQvpMyS1L/P6KvbP4pxz6SlHFnspw0bgeDM7BOgK9JbUAxgGTDazTsDksI2kzsAAoAvQG3hAUtF90QeJ5trtFJbeIT0PWG1mHYG7gdvKvL64/xDOOZcJKqumbZHvwmbtsBjQj2iYD8Lr6WG9H/CUmW00s8XAQqC7pFZAYzObZmYGPFosT9G5JgA9i2rhpV5fvH8G55zLDLUVfymLpFxJHwErgFfNbAbQ0syWAYTXoonOWwNLE7IXhLTWYb14+g55woB8a4DmycrkQds5l1XK0zwiabCkmQnL4MRzmdkWM+sKtCGqNR+c5K1L+hqwJOnJ8pTKe48457JKeXqPmNkoYFSM476V9AZRW/RySa3MbFlo+lgRDisA2iZkawN8FdLblJCemKdAUi2gCbAqWVm8pu2cyyqV2HtkT0m7h/X6wAnAfGAiMCgcNgh4LqxPBAaEHiEdiG445ocmlHWSeoT26vOL5Sk6V39gSmj3LpXXtJ1zWaUSxx5pBYwJPUBygPFm9oKkacB4SXnAEuAsADObK2k8MA8oBIaY2ZZwrkuAR4D6wMthARgNPCZpIVENe0BZhfKg7ZzLKpUVtM3sY+DQEtK/AXqWkmcEMKKE9JnATu3hZraBEPTj8qDtnMsqtX3sEeecyxw+NKtzzmUQD9rOOZdBcr15xDnnMofXtJ1zLoN40HbOuQxSO8sfGfSg7ZzLKj7dmCvV4sVfcfVv7962XbB0BZddfjbnDzqFJx5/mSefmERubi5HH3MY11w7kBeef4t//GPituM/+3QJT//rNg46qD2bNhUy4i+jeS9/Hjk54oqhAzjppB7VcVmuAr5evpq//Xks336zjpwc0fO0HvQ552imTZnFhNGv8OXnKxjx8JXsd1A0NEXh5kJG3TaBRfOXohxxwdDT6XJYRwAWzV/KA395ik0bN3PoEQdxwVWnI4mVy1Yx8uZxrP32exo1bsBlN/6S5i12r87LTktZXtH2oL0rOnTYm2ee/V8AtmzZynHHXswJJ3Rnxow5TJk8k2efu4M6dWrzzTdrAOh76s/pe+rPAfjssyVcPuR2DjqoPQCj/v4MzZo14aVJ97B161bWrPmuxPd06Sk3N5fzLj+NfQ9ow/rvNzD8/93Nj7vvT9t99+Lqmy/godsn7HD85InTAbjj8WtZs2odt1z9MDePvpKcnBwe/t9/Mfi6s+h08D7cevXDfDR9PocecRCP3f88R598OMf0+QlzZi5g7IMvcdmNv6yOy01r2d6mnfRLSZGfSjpT0hlhPcv/SSpm+vTZtG27F3u33pNxT/2bX1/Ujzp1agPQvHmTnY5/6cW36XPKUdu2n33mdS4aHI2LnpOTQ9Omjaum4K5SNN2jMfseEA3kVr9hPVrv05JVK9fQpn1L9t6nxU7HFyxezo8O7wRAk2a70bBRPRbNL2D112tZ//0G9v9ReyRxdO9uvPfmHAC+/Hw5B4c8Xbp1ZOZbc6ro6jJLruIvmajUoC3pJGABcBPQBzgF+COwIOxzCV5+6Z1tQfjzz5fx/vvzGXDO9Qw670Zmz1640/GTXp5Gnz7R8WvXfg/AffeOo/+Z13HV0Lv4+utvq67wrlKtWLaKxQu+pGOXfUo9Zp+Oe/PeW3PYUriFFV99w6JPC/hm+besWrmGZglNHs1a7M7qlWu25Znx+scA5E+dzfofNrJuzfepvZgMVCvHYi+ZKFlN+x7gBDM72cx+HZbewIlhnws2bSrk9Snv06tX1Aa9pXAra9d+x9inRnD1tedx9VV3kzja4sezFlCvXh067d8uOn7LFv7732849LADmPDMbRzSdX/uuP2xarkWt2s2/LCRu64fw6Ar+9GgYb1Sjzuub3eat9id4Xl/Zcxfn2P/H7UnJzeHEkflDD9uB152KvM+WsR1g+7kkw8X0WzPJuTmZnsLbvlV1tCs6SpZm3Ytdpwip8iXRHOllSrM/jAY4IEHb+Ciwf0rXMBM8PZbH9K5cwf22COqIbXcqxknnPhTJPHjH3ckJyeH1avX0axZ1OTxUkKtHGD33Xejfv26nHBCdwB69erBMxOmVP2FuF1SWLiFO69/hJ+ddBg/PfbHSY/NrZXLoCv7bdv+n8H30qrtHjTcrQGrVmz/lbVqxbc03SP63DTbswnX3HIBEH05zHjjYxo0ql/5F5Lhsv1rLNn1/QN4T9J1kn4ZluuAGURjwJbKzEaZ2eFmdni2B2yAl17cMQj37PkTZkyP2hs/X/wVmzcX0rTpbgBs3bqVf78ynZP7bD9eEsce2438/HkATJ8+h/06Jk504dKdmTHy5nG0bt+SvuceU+bxGzdsYsP6jQB8nP8pObm5tOmwF033aEy9BvX4bM4XmBlvTnqfn/w8GtFz7bffsXXrVgD+79HJHNe3e+ouKINJ8ZdMpGSTJEg6iGi24NZEc5kVABPNbF7cNyjcOiszG45iWr9+Iz2Pu4RXXr2f3XZrAETNJf9zwwPM/+QLateuxTW/O48ePaI/vPz8udx955OMHbfjkLtffbmSYdfdz7p139O0WWP+MuJS9t57jyq/nqoyZ/XSsg/KIPNnLeLGS/5Gu/1aofC7+9yL+7B5cyH/vOtZ1n77HQ0b1WefTnvz+79ezIplq7j5qlFIotmeTfjN8LPZs1UzAP7zSdTlb/PGzXQ94kAu/O0ZSGL6lFmMHfkSEhzYdV/yrv4FtetkVwewrs377nIofW/li7Fjzk/2PCXjQnfSoF0Zsj1ou4rJtqDtKkdlBO2ZX8cP2ofvkXlBO1bzj6Sbkm0751y6yJXFXjJR3N9W75ex7ZxzaSHjqs7lFCtom9nzybadcy5dZOoNxrjKbB6RtL+kyZLmhO0fS7oh9UVzzrnyUzmWTBSnTfshYDiwGbbNUFzmNO/OOVcdKuvhGkltJb0u6RNJcyVdGdKbSXpV0oLw2jQhz3BJCyV9KqlXQno3SbPDvnuLhgORVFfSuJA+Q1L7Mq8vxr9BAzPLL5ZWGCOfc85VuUqsaRcCV5vZQUAPYIikzsAwYLKZdQImh23CvgFAF6A38ICk3HCuB4keOOwUlt4hPQ9YbWYdgbuB28oqVJyg/bWk/QALBesPLIuRzznnqlxl1bTNbJmZfRDW1wGfED2z0g8YEw4bA5we1vsBT5nZRjNbDCwEuktqBTQ2s2kW9bF+tFieonNNAHqWNShfnBuRQ4BRwIGSvgQWA7+Kkc8556pcedqqE4fcCEaZ2agSjmsPHEr0RHhLM1sGUWCXVDSMY2tgekK2gpC2mR2HBClKL8qzNJyrUNIaoDnwdWlljhO0vzCzEyQ1BHLCN45zzqWl8gwEFQL0TkE6kaRGwL+AoWa2NklFuKQdliQ9WZ5SxWkeWSxpFFGbjo/M75xLa5XZe0RSbaKA/YSZPROSl4cmD8LripBeALRNyN4G+CqktykhfYc8kmoBTYBVycoUJ2gfALxG1EyyWNL9kn4WI59zzlU5yWIvyc8jEQ2O94mZ3ZWwayIwKKwPAp5LSB8QeoR0ILrhmB+aUtZJ6hHOeX6xPEXn6g9MsTLGFimzecTM1gPjgfGha8s9wFQgN2lG55yrBpU4TvZRwHnAbEkfhbTrgVuJ4mEesAQ4C8DM5n4YR2EAAA1KSURBVEoaD8wj6nkyxMy2hHyXAI8A9YGXwwLRl8JjkhYS1bDL7E4d64lISccA5wAnA+8BZ8fJ55xzVa2yxtM2s7cpvRWlZyl5RgAjSkifCRxcQvoGQtCPq8ygLWkx8BFRbftaM/P5jZxzaSvbH2OPU9M+xMzWprwkzjlXCbI8ZpcetCX9zsxuB0aohBZ7M7sipSVzzrkKqMk17U/C68yqKIhzzlWGLI/ZpQfthOFXfzCzpxP3SSpXw7lzzlWV3CyP2nFutA6Pmeacc9Wusvppp6tkbdonA32A1pLuTdjVGB/lzzmXprK8op20Tfsrovbs09hxerF1wFWpLJRzzlVUjb0RaWazgFmSnjSzzVVYJuecq7Asj9mx+mm3l3QL0BmoV5RoZvumrFTOOVdBlfVEZLqKc33/JJp1oRA4jmgA78dSWSjnnKsoSbGXTBQnaNc3s8mAzOwLM7sJOD61xXLOuYpROf7LRHGaRzZIygEWSLoM+BJoUUYe55yrFlG4yl5xrm4o0AC4AuhGNFThoKQ5nHOu2lTmNAjpJ8542u+F1e+AC1NbHOec2zWZ2uwRV5yhWZ9n5znL1hD14f57GA/WOefSgpTd87PEaR5ZRFTLfigsa4HlwP5h2znn0kgNbx4BDjWzoxO2n5f0ppkdLWluqgrmnHMVke3NI3Fq2ntKale0Edb3CJubUlIq55yrIO/yB1cDb0v6D9HviQ7ApZIaAmNSWTjnnCu/Gt7lz8xeIpoKfmhYDjCzF83sezP7a6oL6Jxz5VGZT0RK+oekFZLmJKQ1k/SqpAXhtWnCvuGSFkr6VFKvhPRukmaHffcqvLmkupLGhfQZktqXVaYyg7akBsC1wGVm9hHQVlLfMq/WOeeqgciJvcTwCNC7WNowYLKZdQImh20kdQYGAF1Cnge0vSvLg8Bgogpwp4Rz5gGrzawjcDdwW1kFijv2yCbgiLBdAPwlRj7nnKsGOeVYkjOzN4FVxZL7sb1peAxwekL6U2a20cwWAwuB7pJaAY3NbJqZGdH4TaeXcK4JQE+V8RMgTtDeL0zwuzlcxHoyta+Mcy7rVcGNyJZmtgwgvBYN69EaWJpwXEFIax3Wi6fvkMfMComegWme7M3jBO1NkuoTHrCRtB+wMUY+55yrcuVp05Y0WNLMhGXwrrx1CWmWJD1ZnlLF6T1yIzCJqC37CeAo4IIY+ZxzrhrEr0Gb2ShgVDnfYLmkVma2LDR9rAjpBUDbhOPaEM0AVhDWi6cn5imQVAtows7NMTuI03vkVeBMokA9FjjczN4oK59zzlUHkRt7qaCJbB80bxDwXEL6gNAjpAPRDcf80ISyTlKP0F59frE8RefqD0wJ7d6lSjaxb7tiSbPDawNJ7cxsSdnX5pxzVasyJzeQNBY4FthDUgFRy8OtwHhJecAS4CwAM5sraTwwj2jSmCFmtiWc6hKinij1gZfDAjAaeEzSQqIa9oAyy1RaUJc0m53bYwzYE2hhZrG+pgq3zsrMeepdSs1ZvbTsg1yN07V5312OuJu2vh875tTJ6ZZxnSqSTez7o8Tt0On7OuAE4OaUlso55yooZv/rjBXn4ZpOkh4hqs6/D3Q2s/tSXTDnnKuYGjrKn6SDgd8TPd1zO5CX0D7jnHNpKVMHgoorWZe/WUSdvl8EuhM92bNtp5ldkdqiOedc+WX7JAjJgvb/q7JSOOdcJamxNW0z82FXnXMZqIYGbeecy0SV2U87HXnQds5lmezu8lfqwzXbDpCOMrN3ykpzZZM0OIx14Nw2/rlw5RHnK6mkPtneT7tidmUEMZe9/HPhYkvWT/sI4EiiiX1/m7CrMVR8pBXnnHMVl6xNuw7QKByzW0L6WqLRqJxzzlWxZF3+pgJTJT1iZl9UYZmymbdbupL458LFFudG5KvAWWb2bdhuSjQPWq+kGZ1zzlW6ODci9ygK2ABmtprtc6I555yrQnGC9tbECREk7UMZc5g555xLjThB+/fA25Iek/QY8CYwPLXFqjhJZ0gySQfGOHaopAa78F4XSLq/lPSVkj6SNE/SRRU4928knZ9wvr0T9j0sqXNFy51wnrMkzZW0VdLhu3q+dJNGn4Wtkn6ckDYnjE9faSR1ldQnYfs0ScMq6dzDJS2U9KkkbxatZnHmiJwEHAaMA8YD3czslVQXbBecC7xNjGl7gKFAhf9QyzDOzLoSTVV0s6SW5clsZiPN7NGweQGwd8K+X5vZvEoo4xyi+T/frIRzpaN0+SwUEFV+UqkrsC1om9lEM7t1V08aKgcDiIZo7g08oGwfRi/NlRq0i2onkg4D2hHNHvwl0C6kpR1JjYhmi88j4Q9VUq6kOyTNlvSxpMslXUEUCF+X9Ho47ruEPP3D5A9IOlXSDEkfSnqtPAHYzFYA/wH2kdQznGO2pH9IqhvOf2uokX8s6Y6QdpOkayT1Bw4Hngg19/qS3pB0uKRLJN2eUOYLJN0X1gdKyg95/l7SH5qZfWJmn8a9lkySZp+FF4Aukg4ooZwnSZom6QNJT4dyI6mPpPmS3pZ0r6QXQnp3Se+G939X0gGS6gB/As4J/7/PKar5S2oi6XNJOSF/A0lLJdWWtJ+kSZLel/RWKb9I+hF1PNhoZouBhURDNbtqkqymfXV4vbOE5Y4Ul6uiTgcmmdlnwKqEL5fBQAfgUDP7MfCEmd1L9EV0nJkdV8Z53wZ6mNmhwFPA7+IWSNK+wL5Eta1HgHPCVG61gEskNQPOALqEsv0lMb+ZTQBmAr8ys65mtj5h9wSimnKRc4Bxkg4K60eF2v4W4FehPA9nY1NICdLps7CVaCKR6xMTJe0B3ACcYGaHEf1//q2kesDfgZPN7GdE87IWmQ8cHd7/D8DNZrYprI8Ln5FxRQeb2RqisfGPCUmnAq+Y2WairoaXm1k34BrggVCu0yT9KRzfmmhc/SIFIc1Vk2T9tC8Kr2V9iNPJucBfw/pTYfsDonktR5pZIYCZrSrnedsQBcNWRA8dLY6R5xxJPwM2AhcT/eEtDkEEYAwwBLgf2AA8LOlFolpZLGa2UtIiST2ABcABwDvhvN2A9xSNeFYfWBHy/Dru+TNcOn0WAJ4Efi+pQ0JaD6Az8E74/1QHmAYcCCwKNVuAsWx/1L0JMEZSJ6IOAbVjvPc4oi/x14l+dTwQavRHAk9r+6h4dSFqWgEmhrSShszzjgjVKNlj7GeWtg/AzJ6p/OJUnKTmwPHAwZKM6FF7k/Q7og9enA9a4jH1EtbvA+4ys4mSjgVuinGucWZ2WUL5upb4hmaFkroDPYn+oC4L1xHXOOBsohrYs2Zmiv4Kx5hZ2t4wTqU0/CwU/X++k2hy7G1FBV41s3OLlf/QJKf6M/C6mZ2h6GbmGzHefiJwS/hV1w2YAjQEvg2/xJIpANombLch+lXiqkmy5pFTw5IHjCb6ef0r4GFgYOqLVm79gUfNbB8za29mbYlqQT8D/g38RlItgPDhBVjHjo/oL5d0UGj/OyMhvQlRez7AoAqWbz7QXlLHsH0e0ROnjYAmZvYS0c2wkv6Iipcz0TNETQHnEgVwgMlAf0ktILpeRV01a4p0/Sw8QlTTL2rumA4cVfSZCO3N+xN9VvbV9h4m55Ty/hckpJf6GTGz74B84B7gBTPbYmZrgcWSzgrvLUmHlJB9IjBAUt3wK6FTOJerJqUGbTO70MwuJKpxdDazX5jZL4juIqejc4Fni6X9C/gl0RfNEuBjSbNCGkRtei8X3XwChhE1T0wBliWc5yain5FvAV9XpHBmtgG4MJxnNlE750iiP7QXJH0MTAWuKiH7I8DIcJOpfrHzrgbmAfuYWX5Im0fUVvrvcN5XgVawY5u2oi5xBcARwIuS0rlXUHmk5WchtD3fS3g4zcxWEgXeseH/03TgwHDf4lJgkqS3geXAmnCa24lqze+w48BtrwOdi25ElvD244gqW+MS0n4F5IV/h7lENx13aNM2s7lEvcbmAZOAIT7Bd/WK8xj7HDM7OGE7B/g4Mc05V7kkNTKz70JT19+ABWZ2d3WXy1W/ODPXvBFqYGOJat0DiL7VnXOpc5GkQUQ3Jz8k6k3iXNk1bYh+RgNHh803zaz4T0/nnHNVIG7Q3gfoZGavKXrUN9fM1qW8dM4553ZQ5mPsisbNmMD2n2etgf9LZaGcc86VLM6AUUOIHgdeC2BmC/ChWZ1zrlrECdobQ1clAEL/Vn8iyjnnqkGcoD1V0vVAfUknAk8Dz6e2WM4550oSp5+2gF8DJxE9dvsK8LDFuYPpnHOuUiUN2v4gjXPOpZekzSNmthWYpYTpxpxzzlWfOE9EtgLmSsoHvi9KNLPTUlYq55xzJYoTtP+Y8lI455yLJdl42vWA3wAdgdnA6KKB451zzlWPUm9EShoHbAbeAk4GvjCzK6uwbM4554pJFrRnh7kMix6oyQ/z2DnnnKsmyXqPbC5a8WYR55xLD8lq2lvY3ltERJPD/hDWzcwaV0kJnXPObRNraFbnnHPpIc7YI84559KEB23nnMsgHrSdcy6DeNB2zrkM4kHbOecyiAdt55zLIP8fVmypg6FnXlYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                        index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92     84577\n",
      "           1       0.80      0.74      0.77     29585\n",
      "\n",
      "    accuracy                           0.89    114162\n",
      "   macro avg       0.86      0.84      0.85    114162\n",
      "weighted avg       0.88      0.89      0.88    114162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probamos otros modelos\n",
    "Probaremos una serie de modelos con sus parametros por defecto, sin tuning:\n",
    "\n",
    "* Decision tree: un árbol de decisión.\n",
    "\n",
    "* Extra trees: Un clasificador de árboles adicionales. Esta clase implementa un meta estimador que se ajusta a una serie de árboles de decisión aleatorios en varias submuestras del conjunto de datos, y utiliza el promedio para mejorar la precisión predictiva y controlar el ajuste excesivo.\n",
    "\n",
    "* Random Forest: Un Random Forest es un conjunto (ensemble) de árboles de decisión combinados con bagging. Es una combinación de árboles predictores tal que cada árbol depende de los valores de un vector aleatorio probado independientemente y con la misma distribución para cada uno de estos.\n",
    "\n",
    "* AdaBoost: consiste en crear varios predictores sencillos en secuencia, de tal manera que el segundo ajuste bien lo que el primero no ajustó, que el tercero ajuste un poco mejor lo que el segundo no pudo ajustar y así sucesivamente.\n",
    "\n",
    "* GradientBoosting: es una técnica de aprendizaje automático utilizado para el análisis de la regresión y para problemas de clasificación estadística, el cual produce un modelo predictivo en forma de un conjunto de modelos de predicción débiles, típicamente árboles de decisión. Construye el modelo de forma escalonada como lo hacen otros métodos de boosting, y los generaliza permitiendo la optimización arbitraria de una función de pérdida diferenciable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador_tree_ = DecisionTreeClassifier(random_state=semilla)\n",
    "clasificador_random_forest = RandomForestClassifier(n_estimators=100, random_state=semilla)\n",
    "clasificador_extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=semilla)\n",
    "clasificador_adaboost = AdaBoostClassifier(random_state=semilla)\n",
    "clasificador_gradientboost = GradientBoostingClassifier(random_state=semilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificadores = [clasificador_tree_, clasificador_random_forest, clasificador_extra_trees, \n",
    "                clasificador_adaboost, clasificador_gradientboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo DecisionTreeClassifier(random_state=1234)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     84577\n",
      "           1       0.70      0.70      0.70     29585\n",
      "\n",
      "    accuracy                           0.84    114162\n",
      "   macro avg       0.80      0.80      0.80    114162\n",
      "weighted avg       0.84      0.84      0.84    114162\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "\n",
      "[[75669  8908]\n",
      " [ 9000 20585]]\n",
      "\n",
      "\n",
      "Entrenando el modelo RandomForestClassifier(random_state=1234)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     84577\n",
      "           1       0.79      0.78      0.79     29585\n",
      "\n",
      "    accuracy                           0.89    114162\n",
      "   macro avg       0.86      0.86      0.86    114162\n",
      "weighted avg       0.89      0.89      0.89    114162\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "\n",
      "[[78554  6023]\n",
      " [ 6450 23135]]\n",
      "\n",
      "\n",
      "Entrenando el modelo ExtraTreesClassifier(random_state=1234)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93     84577\n",
      "           1       0.80      0.78      0.79     29585\n",
      "\n",
      "    accuracy                           0.89    114162\n",
      "   macro avg       0.86      0.85      0.86    114162\n",
      "weighted avg       0.89      0.89      0.89    114162\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "\n",
      "[[78671  5906]\n",
      " [ 6644 22941]]\n",
      "\n",
      "\n",
      "Entrenando el modelo AdaBoostClassifier(random_state=1234)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     84577\n",
      "           1       0.79      0.76      0.78     29585\n",
      "\n",
      "    accuracy                           0.89    114162\n",
      "   macro avg       0.86      0.84      0.85    114162\n",
      "weighted avg       0.88      0.89      0.89    114162\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "\n",
      "[[78770  5807]\n",
      " [ 7170 22415]]\n",
      "\n",
      "\n",
      "Entrenando el modelo GradientBoostingClassifier(random_state=1234)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93     84577\n",
      "           1       0.79      0.79      0.79     29585\n",
      "\n",
      "    accuracy                           0.89    114162\n",
      "   macro avg       0.86      0.86      0.86    114162\n",
      "weighted avg       0.89      0.89      0.89    114162\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "\n",
      "[[78377  6200]\n",
      " [ 6229 23356]]\n",
      "\n",
      "\n",
      "CPU times: user 28min 36s, sys: 34.2 s, total: 29min 10s\n",
      "Wall time: 36min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for clasificador in clasificadores:\n",
    "    print(f'Entrenando el modelo {clasificador}')\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', clasificador)\n",
    "                              ])\n",
    "\n",
    "    # Preprocesamiento de datos de entrenamiento, ajuste del modelo\n",
    "    my_pipeline.fit(X_train, y_train)\n",
    "    # Preprocesamiento de datos de validación, obtener predicciones\n",
    "    preds = my_pipeline.predict(X_test)\n",
    "    # Calculamos la matriz de confusión\n",
    "    cmx = confusion_matrix(y_test,preds)\n",
    "    # Mostramos las métricas de evaluación\n",
    "    print(classification_report(y_test, preds)+'\\n')\n",
    "    print('Matriz de confusión:\\n') \n",
    "    print(cmx)\n",
    "    print('\\n') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
